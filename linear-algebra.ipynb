{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": "\n# Linear Algebra\n\n## Scalars, Vectors, Matrics and Tensors\n\n1. **Scalars** - A scalar is just a single number.\n\n2. **Vectors** - A vector is an array of numbers. Number in \narray identified using its index in the ordering. We can think \nof vectors as identifying points in space, each element in the\nvector giving the coordinates along a different axis.\n\n3. **Matrices** - A matrix is a 2-D array of numbers, so each\nelement is identified by two indices instead of just one.\n**_A\u003csub\u003ei, :\u003c/sub\u003e_** represents a row of the matrix. \n\n4. **Tensors** - An array fo numbers on a regular gird with a\nvariable number of axes is known as a tensor.\n\n\n### Matrix operations\n\nTranspose of a matrix is the mirror image of the matrix across a\ndiagonal line called the main diagonal. Starting from the upper-left\ncorner and going down and to the right. It essentially puts the\nelement at position *(i, j)* of a matrix to be at position\n*(j, i)* of the transpose.\n\n**_C_** \u003d **_A_** + **_B_** corresponds to the addition of two\nmatrices. This is only possible as long as the two matrices have\nthe same shape. This operation corresponds to adding elements\nat position *(i, j)* of A and B and assigning their sum to the\n*(i, j)* element of C. \n\nAdding or multiplying a scalar to a matrix corresponds to performing\nthe operation on every element of the matrix. \n\n\nBroadcasting is a less conventional notation used in deep learning\nwherein we allow the addition of a matrix to a vector yielding another\nmatrix. Here this operation corresponds to C\u003csub\u003ei, j\u003c/sub\u003e \u003d A\u003csub\u003ei, \nj\u003c/sub\u003e + b\u003csub\u003ej\u003c/sub\u003e. Vector b gets added to each row of the matrix.\n\nMatrix multiplication - the produce of matrices A and B is C. In order\nfor this product ot be defined A must have the same number of columns\nas B has rows. If A is of shape $m \\times n $ and B is of shape \n$n \\times p$ then C will be of shape $m \\times p$. The notation for\nmatrix product is simply **_C \u003d AB _** where the product operation\nis defined by $C_{i, j} \u003d \\sum_{k} A_{i, k} B_{k, j} $.\n\nThe Hadamard product is denoted by A âŠ™ B and is the element-wise product\nof two matrices. The dot product between two vectors x and y of the same\ndimensionality is the matrix product $x^{T}y$. We can think of the matrix\nproduct C \u003d AB as computing $C_{i, j}$ the dot product between row i of A\nand column j of B.\n\nMatrix products have the following mathematical properties:\n\n* Distributive\n* Associative\n\nMatrix multiplication is not commutative but the dot product between two\nvectors is commutative.\n\n$(AB)^{T} \u003d B^{T}A$\n\n$Ax \u003d B$\n\nTo solve this system of linear equations Linear Algebra provides us with the\nmatrix inversion operation. \n\n\n\n\n\n    \n    \n    \n    \n## Suggested Resources\n\n[The Matrix Cookbook](https://www.ics.uci.edu/~welling/teaching\\/KernelsICS273B/MatrixCookBook.pdf)\n\n[Shilov](https://cosmathclub.files.wordpress.com/2014/10/georgi-shilov-linear-algebra4.pdf)\n\n"
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "kernelspec": {
      "name": "python2",
      "language": "python",
      "display_name": "Python 2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}